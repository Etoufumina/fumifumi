import streamlit as st
import spacy
import subprocess
import sys
 
# spaCyãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒã‚§ãƒƒã‚¯
@st.cache_resource
def load_spacy_model():
    try:
        nlp = spacy.load("en_core_web_sm")
    except OSError:
        st.info("è‹±èªãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
        subprocess.check_call([sys.executable, "-m", "spacy", "download", "en_core_web_sm"])
        nlp = spacy.load("en_core_web_sm")
    return nlp
 
# spaCyãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
nlp = load_spacy_model()
 
st.title("è‹±æ–‡SVOæŠ½å‡ºã‚¢ãƒ—ãƒª")
 
# ã‚µãƒ³ãƒ—ãƒ«æ–‡ã®æä¾›
sample_text = """John reads books.
Mary likes coffee.
The cat chased the mouse in the garden.
Students are studying mathematics.
She gave him a present."""
 
text = st.text_area(
    "è‹±æ–‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", 
    value=sample_text,
    height=200,
    help="è‹±æ–‡ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€SVOï¼ˆä¸»èªãƒ»å‹•è©ãƒ»ç›®çš„èªï¼‰æ§‹é€ ã‚’æŠ½å‡ºã—ã¾ã™"
)
 
def extract_svo(doc):
    """
    æ”¹è‰¯ç‰ˆSVOæŠ½å‡ºé–¢æ•°
    å„å‹•è©ã‚’ä¸­å¿ƒã«ã€ãã®ä¸»èªã¨ç›®çš„èªã‚’æ­£ã—ãé–¢é€£ä»˜ã‘ã¦æŠ½å‡º
    """
    svos = []
    for sent in doc.sents:
        # å„æ–‡ã«ã¤ã„ã¦å‡¦ç†
        for token in sent:
            # å‹•è©ã‚’ä¸­å¿ƒã«æ¢ç´¢ï¼ˆROOTã¾ãŸã¯å‹•è©ï¼‰
            if token.pos_ == "VERB" or token.dep_ == "ROOT":
                subject = None
                verb = token.text
                obj = None
                # ã“ã®å‹•è©ã®å­è¦ç´ ã‹ã‚‰ä¸»èªã¨ç›®çš„èªã‚’æ¢ã™
                for child in token.children:
                    # ä¸»èªã®æ¤œå‡ºï¼ˆnsubj, nsubjpassãªã©ï¼‰
                    if "subj" in child.dep_:
                        # è¤‡åˆä¸»èªã®å ´åˆã€å…¨ä½“ã‚’å–å¾—
                        subject = get_compound_phrase(child)
                    # ç›´æ¥ç›®çš„èªã®æ¤œå‡ºï¼ˆdobjï¼‰
                    elif child.dep_ == "dobj":
                        obj = get_compound_phrase(child)
                    # å‰ç½®è©ç›®çš„èªã®æ¤œå‡ºï¼ˆpobjï¼‰- ç›®çš„èªãŒãªã„å ´åˆã®ä»£æ›¿
                    elif child.dep_ == "pobj" and obj is None:
                        obj = get_compound_phrase(child)
                # åŠ©å‹•è©ãŒã‚ã‚‹å ´åˆã€å‹•è©å¥å…¨ä½“ã‚’å–å¾—
                verb_phrase = get_verb_phrase(token)
                if verb_phrase:
                    verb = verb_phrase
                # SVOæ§‹é€ ãŒå®Œæˆã—ã¦ã„ã‚‹å ´åˆã®ã¿è¿½åŠ 
                if subject and verb and obj:
                    svos.append((subject, verb, obj))
    return svos
 
def get_compound_phrase(token):
    """
    è¤‡åˆèªå¥ï¼ˆå½¢å®¹è©ä¿®é£¾ãªã©ï¼‰ã‚’å«ã‚€å®Œå…¨ãªãƒ•ãƒ¬ãƒ¼ã‚ºã‚’å–å¾—
    """
    phrase_parts = []
    # å·¦å´ã®ä¿®é£¾èªã‚’å–å¾—
    for child in token.children:
        if child.dep_ in ["compound", "amod", "det", "poss"]:
            if child.i < token.i:  # ãƒˆãƒ¼ã‚¯ãƒ³ã®å‰ã«ã‚ã‚‹å ´åˆ
                phrase_parts.append(child.text)
    # ãƒ¡ã‚¤ãƒ³ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¿½åŠ 
    phrase_parts.append(token.text)
    # å³å´ã®ä¿®é£¾èªã‚’å–å¾—
    for child in token.children:
        if child.dep_ in ["compound", "prep"]:
            if child.i > token.i:  # ãƒˆãƒ¼ã‚¯ãƒ³ã®å¾Œã«ã‚ã‚‹å ´åˆ
                phrase_parts.append(child.text)
    return " ".join(phrase_parts)
 
def get_verb_phrase(token):
    """
    åŠ©å‹•è©ã‚’å«ã‚€å‹•è©å¥å…¨ä½“ã‚’å–å¾—
    """
    verb_parts = []
    # åŠ©å‹•è©ã‚’æ¢ã™
    for child in token.children:
        if child.dep_ in ["aux", "auxpass"] and child.i < token.i:
            verb_parts.append(child.text)
    # å‹•è©è‡ªä½“ã‚’è¿½åŠ 
    verb_parts.append(token.text)
    # å‹•è©å¥ãŒã‚ã‚‹å ´åˆã®ã¿è¿”ã™
    if len(verb_parts) > 1:
        return " ".join(verb_parts)
    return None
 
# ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¡¨ç¤ºã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³
show_debug = st.checkbox("è©³ç´°ãªè§£æçµæœã‚’è¡¨ç¤º", value=False)
 
if st.button("SVOã‚’æŠ½å‡º", type="primary"):
    if text:
        doc = nlp(text)
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®è¡¨ç¤º
        if show_debug:
            st.subheader("ä¾å­˜æ§‹é€ è§£æçµæœï¼š")
            for sent in doc.sents:
                st.write(f"**æ–‡:** {sent.text}")
                debug_data = []
                for token in sent:
                    debug_data.append({
                        "å˜èª": token.text,
                        "å“è©": token.pos_,
                        "ä¾å­˜é–¢ä¿‚": token.dep_,
                        "è¦ª": token.head.text if token.head != token else "ROOT"
                    })
                st.table(debug_data)
        # SVOæŠ½å‡º
        svos = extract_svo(doc)
        if svos:
            st.subheader("ğŸ¯ æŠ½å‡ºã•ã‚ŒãŸSVOæ§‹é€ ï¼š")
            for i, (s, v, o) in enumerate(svos, 1):
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.info(f"**ä¸»èª:** {s}")
                with col2:
                    st.success(f"**å‹•è©:** {v}")
                with col3:
                    st.warning(f"**ç›®çš„èª:** {o}")
        else:
            st.warning("SVOæ§‹é€ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚å®Œå…¨ãªSVOæ§‹é€ ã‚’æŒã¤æ–‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            st.info("ğŸ’¡ ãƒ’ãƒ³ãƒˆ: ã€ŒSubject + Verb + Objectã€ã®å½¢å¼ã®æ–‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ä¾‹: 'John reads books.'")
    else:
        st.error("è‹±æ–‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
 
# ä½¿ã„æ–¹ã®èª¬æ˜
with st.expander("ğŸ“– ä½¿ã„æ–¹"):
    st.markdown("""
    ### ã“ã®ã‚¢ãƒ—ãƒªã«ã¤ã„ã¦
    ã“ã®ã‚¢ãƒ—ãƒªã¯ã€è‹±æ–‡ã‹ã‚‰**SVOï¼ˆä¸»èªãƒ»å‹•è©ãƒ»ç›®çš„èªï¼‰**æ§‹é€ ã‚’è‡ªå‹•çš„ã«æŠ½å‡ºã—ã¾ã™ã€‚
    ### å¯¾å¿œã™ã‚‹æ–‡ã®ä¾‹ï¼š
    - âœ… John reads books. ï¼ˆã‚¸ãƒ§ãƒ³ã¯æœ¬ã‚’èª­ã‚€ï¼‰
    - âœ… The cat chased the mouse. ï¼ˆçŒ«ãŒãƒã‚ºãƒŸã‚’è¿½ã„ã‹ã‘ãŸï¼‰
    - âœ… She is writing a letter. ï¼ˆå½¼å¥³ã¯æ‰‹ç´™ã‚’æ›¸ã„ã¦ã„ã‚‹ï¼‰
    ### æ³¨æ„äº‹é …ï¼š
    - å®Œå…¨ãªSVOæ§‹é€ ã‚’æŒã¤æ–‡ã®ã¿ãŒæŠ½å‡ºã•ã‚Œã¾ã™
    - è¤‡é›‘ãªæ–‡ç« ã®å ´åˆã€ã™ã¹ã¦ã®SVOæ§‹é€ ãŒæŠ½å‡ºã•ã‚Œãªã„å ´åˆãŒã‚ã‚Šã¾ã™
    - å—å‹•æ…‹ã‚„ç‰¹æ®Šãªæ§‹æ–‡ã«ã¯å¯¾å¿œã—ã¦ã„ãªã„å ´åˆãŒã‚ã‚Šã¾ã™
    """)