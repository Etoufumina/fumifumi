import streamlit as st
import spacy
import en_core_web_sm  # ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

# Streamlit Shareç”¨ã®ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
@st.cache_resource
def load_spacy_model():
    """Streamlit Shareç’°å¢ƒã§ã‚‚å‹•ä½œã™ã‚‹ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿"""
    try:
        # æ–¹æ³•1: ç›´æ¥èª­ã¿è¾¼ã¿ï¼ˆStreamlit Shareæ¨å¥¨ï¼‰
        nlp = en_core_web_sm.load()
    except:
        try:
            # æ–¹æ³•2: é€šå¸¸ã®èª­ã¿è¾¼ã¿ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒï¼‰
            nlp = spacy.load("en_core_web_sm")
        except:
            st.error("spaCyãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            st.stop()
    return nlp

# spaCyãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
nlp = load_spacy_model()

st.title("ğŸ” è‹±æ–‡SVOæŠ½å‡ºã‚¢ãƒ—ãƒª")
st.markdown("è‹±æ–‡ã‹ã‚‰**ä¸»èª(Subject)ãƒ»å‹•è©(Verb)ãƒ»ç›®çš„èª(Object)**ã‚’è‡ªå‹•æŠ½å‡ºã—ã¾ã™")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«èª¬æ˜ã‚’è¿½åŠ 
with st.sidebar:
    st.header("ğŸ“– ä½¿ã„æ–¹")
    st.markdown("""
    1. è‹±æ–‡ã‚’å…¥åŠ›æ¬„ã«å…¥åŠ›
    2. ã€ŒSVOã‚’æŠ½å‡ºã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
    3. æŠ½å‡ºã•ã‚ŒãŸSVOæ§‹é€ ã‚’ç¢ºèª
    
    ### å¯¾å¿œã™ã‚‹æ–‡ã®ä¾‹ï¼š
    - John reads books.
    - Mary likes coffee.
    - The cat chased the mouse.
    """)
    
    st.header("â„¹ï¸ About")
    st.markdown("""
    ã“ã®ã‚¢ãƒ—ãƒªã¯spaCyã®è‡ªç„¶è¨€èªå‡¦ç†ã‚’ä½¿ç”¨ã—ã¦
    è‹±æ–‡ã®æ§‹é€ ã‚’è§£æã—ã¦ã„ã¾ã™ã€‚
    
    [GitHub](https://github.com/yourusername/yourrepo)
    """)

# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
sample_text = """John reads books.
Mary likes coffee.
The cat chased the mouse in the garden.
Students are studying mathematics.
She gave him a present."""

text = st.text_area(
    "è‹±æ–‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", 
    value=sample_text,
    height=150,
    help="è‹±æ–‡ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€SVOæ§‹é€ ã‚’æŠ½å‡ºã—ã¾ã™"
)

def extract_svo(doc):
    """æ”¹è‰¯ç‰ˆSVOæŠ½å‡ºé–¢æ•°"""
    svos = []
    
    for sent in doc.sents:
        for token in sent:
            if token.pos_ == "VERB" or token.dep_ == "ROOT":
                subject = None
                verb = token.text
                obj = None
                
                for child in token.children:
                    if "subj" in child.dep_:
                        subject = get_compound_phrase(child)
                    elif child.dep_ == "dobj":
                        obj = get_compound_phrase(child)
                    elif child.dep_ == "pobj" and obj is None:
                        obj = get_compound_phrase(child)
                
                verb_phrase = get_verb_phrase(token)
                if verb_phrase:
                    verb = verb_phrase
                
                if subject and verb and obj:
                    svos.append((subject, verb, obj))
    
    return svos

def get_compound_phrase(token):
    """è¤‡åˆèªå¥ã‚’å«ã‚€å®Œå…¨ãªãƒ•ãƒ¬ãƒ¼ã‚ºã‚’å–å¾—"""
    phrase_parts = []
    
    for child in token.children:
        if child.dep_ in ["compound", "amod", "det", "poss"]:
            if child.i < token.i:
                phrase_parts.append(child.text)
    
    phrase_parts.append(token.text)
    
    for child in token.children:
        if child.dep_ in ["compound", "prep"]:
            if child.i > token.i:
                phrase_parts.append(child.text)
    
    return " ".join(phrase_parts)

def get_verb_phrase(token):
    """åŠ©å‹•è©ã‚’å«ã‚€å‹•è©å¥å…¨ä½“ã‚’å–å¾—"""
    verb_parts = []
    
    for child in token.children:
        if child.dep_ in ["aux", "auxpass"] and child.i < token.i:
            verb_parts.append(child.text)
    
    verb_parts.append(token.text)
    
    if len(verb_parts) > 1:
        return " ".join(verb_parts)
    return None

# ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¡¨ç¤ºã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³
show_debug = st.checkbox("è©³ç´°ãªè§£æçµæœã‚’è¡¨ç¤º", value=False)

# æŠ½å‡ºãƒœã‚¿ãƒ³
col1, col2, col3 = st.columns([1, 2, 1])
with col2:
    extract_button = st.button("ğŸ¯ SVOã‚’æŠ½å‡º", type="primary", use_container_width=True)

if extract_button:
    if text:
        with st.spinner('è§£æä¸­...'):
            doc = nlp(text)
            
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®è¡¨ç¤º
            if show_debug:
                st.subheader("ä¾å­˜æ§‹é€ è§£æçµæœï¼š")
                for sent in doc.sents:
                    with st.expander(f"æ–‡: {sent.text[:50]}..."):
                        debug_data = []
                        for token in sent:
                            debug_data.append({
                                "å˜èª": token.text,
                                "å“è©": token.pos_,
                                "ä¾å­˜é–¢ä¿‚": token.dep_,
                                "è¦ª": token.head.text if token.head != token else "ROOT"
                            })
                        st.table(debug_data)
            
            # SVOæŠ½å‡º
            svos = extract_svo(doc)
            
            if svos:
                st.subheader("âœ¨ æŠ½å‡ºã•ã‚ŒãŸSVOæ§‹é€ ")
                
                for i, (s, v, o) in enumerate(svos, 1):
                    with st.container():
                        st.markdown(f"### æ–‡ {i}")
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("ä¸»èª (S)", s)
                        with col2:
                            st.metric("å‹•è© (V)", v)
                        with col3:
                            st.metric("ç›®çš„èª (O)", o)
                        st.markdown("---")
                
                # çµæœã®ã‚µãƒãƒªãƒ¼
                st.success(f"âœ… {len(svos)}å€‹ã®SVOæ§‹é€ ã‚’æŠ½å‡ºã—ã¾ã—ãŸï¼")
            else:
                st.warning("âš ï¸ SVOæ§‹é€ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                st.info("""
                ğŸ’¡ **ãƒ’ãƒ³ãƒˆ:** 
                - å®Œå…¨ãªSVOæ§‹é€ ã‚’æŒã¤æ–‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„
                - ä¾‹: "John reads books." "She loves music."
                """)
    else:
        st.error("âŒ è‹±æ–‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center'>
        <small>Made with â¤ï¸ using Streamlit and spaCy</small>
    </div>
    """,
    unsafe_allow_html=True
)